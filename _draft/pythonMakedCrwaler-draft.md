---
layout: post
title: "[Python] 크롤링으로 업무 자동화하기 - (1)개요"
date: 2019-11-25 10:00:00
category: python
tag: 
- python
comments: true
---

어느날 협업팀에서 API 서비스 명세서 정보가 변경되었는데, 우리팀에 내용이 전달되지 않아 문제가 발생하는 일이 있었다. 긴급하게 수정하여 문제를 해결했지만, 사람이하는 일이기 때문에 언젠가는 또 발생할 수 있는 일이였다.  
그래서 나는 수 많은 명세서의 변경을 확인하여 결과를 알려주는 크롤러를 만들었다.

### 이슈
현재 팀에서 제공하는 API는 엔진을 관리하는 팀과의 협업으로 개발&운영 되고 있다. 그리고 이 두팀간의 상호소통은 매우 중요하다. 대표적으로 서비스 명세서가 있다. 근데 이 서비스 명세서의 변경된 내용이 전달되지 않아 API에 문제가 발생했었다.

협업팀에서 관리하는 API 서비스 명세서의 수는 대략 50개 가까이된다. 그리고 각 명세서 파일의 첫번째 시트에 명세서의 변경된 내용을 로그로 남긴다.

근데 이 변경된 내용이 우리팀에게도 매우 중요하다. 어떤건 API 서비스에 직접적인 문제를 일으킬 수 있을 정도로 크리티컬할 수 있다. 그래서 항상 명세서 정보의 변경을 인지하고 있어야 한다.

매일 변경을 인지하기 위해 사람이 직접 조치를 취하는 방법을 생각해보았다.

- 변경 즉시 협업팀이 우리팀에게 내용을 전달한다.
- 매일 특정 시간마다 파일들을 다운 받아 이전 버전과 비교한다.

말은 참 간단하다. 하지만 이 방법은 현실적으로 문제가 있다.

- ~~변경 즉시 협업팀이 우리팀에게 내용을 전달한다.~~ 사람은 실수할 수 있고, 실제로 문제가 발생했다.
- ~~매일 특정 시간마다 파일들을 다운 받아 이전 버전과 비교한다.~~ 한번 할때마다 1~2시간 정도 소요될 수 있는 업무다. 오전, 오후 두번한다고 하면 그건 꽤 큰 리소스 낭비다. (그리고 누가 이걸하고 싶겠나)

현실적인 어려움이 있는 이 문제를 해결하기 위해 1차적으로 협업팀에서 메일 전송을 해주기로 했다. 그런데 실제 중요한 변경만 공유됐고 사소한 변화까지는 공유되지 못하고 있었다.

하지만 나는 사소한 변화도 우리팀이 인지해야 된다고 생각했고, 가능한한 꼼꼼하게 조치를 취해야 된다고 생각했다. 그래서 나는 개발자답게 컴퓨터에게 업무를 지시하기로 결정했다. '매일 오전, 오후 두번 모든 명세서를 비교해서 우리에게 변경사항을 알려줘'라고 말이다.

### 기대효과
컴퓨터가 이 업무를 대신했을때 기대효과는 이러하다.

- 우리가 업무를 잊고있어도 컴퓨터는 문제가 발생하지 않는 이상 잊어버리지 않는다.
- 문제가 발생해도 문제가 발생했다고 알려준다.
- 사람이 1~2시간이라는 시간이 필요할때, 컴퓨터는 1분안에 해결할 수 있다.
- 정말 귀찮고 하기 싫은 일을 군말없이 한다.
- 팀원 모두는 더 생산적인 일에 집중할 수 있다.


### 구체적인 업무내용
명세서가 존재하는 페이지에 접근하려면 먼저 로그인을 해야한다.

![crawlerProcess1](/assets/images/post/crawlerProcess1.png){: width="100%"}*\<로그인 페이지\>*

그리고 서비스 명세서를 우클릭해서 다운로드한다.

![crawlerProcess2](/assets/images/post/crawlerProcess2.png){: width="100%"}*\<명세서 다운로드\>*

이렇게 간단하다. 로그인하고 다운로드하면 끝이다. 그리고 다운로드한 디렉토리는 zip파일로 다운로드되고 이를 풀어주면 아래와 같다.

![crawlerProcess3](/assets/images/post/crawlerProcess3.png){: width="100%"}*\<명세서 다운로드 결과\>*

그리고 명세서 내용은 대략 아래와 같이 구성되어 있다. 앞에서도 언급했듯이 이런 파일이 50개 가까이되고 데이터가 많은 파일도 있다.

![crawlerProcess4](/assets/images/post/crawlerProcess4.png){: width="100%"}*\<명세서 내용 예시\>*

이 데이터들이 수정, 삭제, 추가된 것을 파악하면 된다.

그리고 이 파악된 정보는 현재 팀내에서 사용중인 **슬랙**으로 전송해주면 된다.

![crawlerProcess5](/assets/images/post/crawlerProcess5.png){: width="100%"}*\<슬랙에 결과 전송\>*

이렇게 내용을 전송하고 다음 비교때 사용하기 위해 현재 받은 파일을 백업하면 마무리된다.

간단하게 정리하면 아래와 같다.

1. 페이지 로그인
2. 서비스 명세서 디렉토리 다운로드
3. 다운로드된 zip파일 풀기
4. 파일 비교한 결과 슬랙으로 전송
5. 다음 파일 비교를 위해 현재 버전 백업



### 사용한 기술
#### 파이썬
파이썬은 생산성이 좋고 라이브러리가 매우 훌륭하여 자주 사용하는 프로그래밍 언어다. 특히 높은 생산성과 예쁜 코드 때문에 개인적으로 좋아하는 언어이기도 하다.

앞에서 설명한 업무를 자동화 할때 파이썬이 편하다고 생각해서 사용했다. 크롤링할 때 selenium과 BeautifulSoup를 같이 사용하면 크롤링한 데이터를 다루는데 편리하고, 엑셀을 다룰때 openpyxl이나, pandas같은 라이브러리로 엑셀 데이터를 쉽게 다룰 수 있기 때문이다. 그리고 언급한 라이브러리들의 레퍼런스가 많고 좋다.

#### Selenium
동적 렌더링 페이지를 크롤링하기 위해서 webdriver를 사용해야 했다. 그래서 유명하고 레퍼런스도 많은 Selenium을 선택했고, 드라이버는 크롬드라이버를 선택했다.

#### pandas
이전에 파이썬으로 엑셀 파일을 조작하기 위해 openpyxl을 사용했었다. 이번에는 머신러닝 공부하면서 조금 다뤄봤었던 pandas를 사용했다. 이유는 그냥 사용해보고 싶었다. (근데 다 만들고 나니 판다스로 한게 별로 없다.)

#### slacker
파이썬 프로세스에서 슬랙으로 메세지를 전송하기 위한 라이브러리이다. 현재 팀에서 슬랙을 사용하고 있기 때문에 사용해야했다.

